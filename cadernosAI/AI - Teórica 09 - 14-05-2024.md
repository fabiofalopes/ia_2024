Lower case 
Reg ex - clean símbolos, pontos, eojis etx 
Palavas com acento -> sem acento
Stop words (que, e, etc...) -> lib python com listas por lingua (nao contribuen semanticamente para o corpus)
Transformação de palavras para so um tipo (exemplo, verbos (encontar raiz etimologica da palavra))

--- 
```
"Refogamos as cebolas até que obtenham uma cor dourada. Assim que a cebola estiver pronta, adicionamos a batata cortada em lascas. Quando a batata estiver macia, incorporamos os ovos mexidos.", 

"Corte quatro cebolas em cubos pequenos e refogue as. 
Em seguida, adicione a carne picada, desfazendo-a com as mãos para evitar blocos grandes, e logo em seguida, acrescente a batata em cubos."

```


**1º Lower Case**

```
"refogamos as cebolas até que obtenham uma cor dourada. assim que a cebola estiver pronta, adicionamos a batata cortada em lascas. quando a batata estiver macia, incorporamos os ovos mexidos.", 

"corte quatro cebolas em cubos pequenos e refogue-as. em seguida, adicione a carne picada, desfazendo-a com as mãos para evitar blocos grandes, e logo em seguida, acrescente a batata em cubos."

```

**2º Reg ex para remoção de pontos, virgulas...**  ficar apenas com caracteres de [a-z] e whitespaces
```
"refogamos as cebolas até que obtenham uma cor dourada assim que a cebola estiver pronta adicionamos a batata cortada em lascas quando a batata estiver macia incorporamos os ovos mexidos", 

"corte quatro cebolas em cubos pequenos e refogue as em seguida adicione a carne picada desfazendo a com as mãos para evitar blocos grandes e logo em seguida acrescente a batata em cubos"

```

**3º Palavas com acento -> sem acento**
```
"refogamos as cebolas ate que obtenham uma cor dourada assim que a cebola estiver pronta adicionamos a batata cortada em lascas quando a batata estiver macia incorporamos os ovos mexidos", 

"corte quatro cebolas em cubos pequenos e refogue as em seguida adicione a carne picada desfazendo a com as maos para evitar blocos grandes e logo em seguida acrescente a batata em cubos"

```

# Entre estes steps: tokenise! (fazer split por words)

4º Remove stop words (que, e, etc...) -> lib python com listas por lingua (nao contribuen semanticamente para o corpus)
```
"refogamos cebolas ate obtenham uma cor dourada assim cebola estiver pronta adicionamos a batata cortada em lascas quando a batata estiver macia incorporamos os ovos mexidos", 

"corte quatro cebolas cubos pequenos refogue seguida adicione carne picada desfazendo com maos para evitar blocos grandes logo seguida acrescente  batata cubos"

```


5º lematizar - trocas entre parenthesises 
```
"refogamos (refogar) cebolas (cebola) ate obtenham (obter) uma (um) cor dourada (dourado) assim cebola estiver (estar) pronta (pronto) adicionamos (adicionar) batata cortada (cortado) (cortar) lascas (lasca) quando a batata estiver (estar) macia incorporamos (incorporar) ovos (ovo) mexidos (mexido)", 

"corte quatro cebolas em cubos pequenos e refogue as em seguida adicione a carne picada desfazendo a com as maos para evitar blocos grandes e logo em seguida acrescente a batata em cubos"

```

No final temos uma lista de listas de documentos já com pré processamento

Agregar listas e fazer set para ter ocorrências dos tokens no corpus

---
Matriz. TF IDF
- linhas: cada palavra por linha 
- colunas: docs 

$m$ x $n$ 
m: vocabolario 
n: # docs

**Metodos:** 
- LDA 
- NMF

após isso resulta matrix $m$ x $k$  * $k$ x $n$ 

![[Screenshot_20240514_210510.png]]

Tópico definido com base no vocabulario (faturização da matriz)

Só sai até a construção da matriz 

