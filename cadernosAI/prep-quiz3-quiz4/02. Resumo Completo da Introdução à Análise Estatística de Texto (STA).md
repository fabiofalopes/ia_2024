# Resumo Completo da Introdução à Análise Estatística de Texto (STA)

## 12.1 Introdução à Análise Estatística de Texto

A análise de texto é fundamental, uma vez que o texto é uma das formas mais comuns de media presentes em todo o lado, como em livros, websites, etc. Derivar significado do texto é uma tarefa complexa, pois a semântica em sistemas inteligentes é criada pela distribuição de palavras, seguindo regras gramaticais específicas e diversos padrões linguísticos. Além disso, fatores como códigos culturais, abreviaturas, metáforas, analogias, ironia e a forma como as pessoas escrevem online complicam a extração de semântica a partir de lexis.

## 12.2 O Pipeline Bag-of-Words (Saco de Palavras)

O modelo Bag-of-Words (BoW) processa textos em quatro etapas principais:

1. **Pré-processamento**: 
    - Remove pontuação, números, emojis e outros caracteres não relevantes.
    - Converte todo o texto para minúsculas.
    - Substitui caracteres acentuados pelas suas variantes sem acento.
    - Etapas adicionais podem incluir a manutenção de maiúsculas dependendo do contexto.

2. **Tokenização**: 
    - Divide o documento em palavras (tokens).
    - Remove palavras de função gramatical estritamente (stop words).

3. **Cálculo do TF-IDF**: 
    - Calcula a frequência dos termos no documento (TF).
    - Calcula a importância dos termos no corpus (IDF) usando a fórmula: 
		$$ \text{IDF}_t = \log \left( \frac{N}{d_t} \right)$$
      onde \( N \) é o número total de documentos e \( d_t \) é o número de documentos que contêm o termo \( t \).

4. **Construção da Matriz TF-IDF**:
    - Representa cada documento como um vetor de frequências de termos no espaço de todas as palavras do corpus.

## 12.3 Pré-processamento

### Etapas Detalhadas do Pré-processamento

1. **Remoção de Carateres Irrelevantes**:
    - Eliminação de pontuação, números, emojis e outros caracteres que não são de interesse.
  
2. **Conversão para Minúsculas**:
    - Todo o texto é convertido para minúsculas para uniformizar o corpus.
  
3. **Substituição de Carateres Acentuados**:
    - Os caracteres com acentos são substituídos pelas suas variantes sem acento.

### Etapa Intermédia
Antes da tokenização, uma etapa intermédia pode ser incluída dependendo dos objetivos da análise.

2. **Tokenização**:
    - A cadeia de caracteres que representa o documento é transformada numa lista das suas palavras componentes.

3. **Remoção de Stop Words**:
    - Remoção de palavras de função gramatical (stop words) que não contribuem para a compreensão do conteúdo.

4. **Lematização ou Stemming**:
    - **Lematização**: Normaliza diferentes formas de uma palavra para a sua raiz. Por exemplo, "mapeado", "mapeando", "mapeador" e "mapas" são todos normalizados para "map".
    - **Stemming**: Remove os sufixos das palavras, reduzindo-as à sua raiz etimológica.

5. **Construção do Dicionário Universal**:
    - Criação de uma lista de todos os termos que aparecem pelo menos uma vez em pelo menos um documento do corpus.

## 12.4.2 Frequência Inversa de Documentos: IDF

A TF (Term Frequency) só indica quantas vezes um termo aparece em um documento, mas para analisar o corpus, precisamos da importância desses termos. A Frequência Inversa de Documentos (IDF) ajuda a representar a importância dos termos, mitigando a influência de termos comuns que aparecem em muitos documentos.

### Cálculo do IDF
$$\text{IDF}_t = \log \left( \frac{N}{d_t} \right)$$ 

onde \( N \) é o número total de documentos e \( d_t \) é o número de documentos que contêm o termo \( t \).

Ao comparar dois documentos, o TF-IDF coloca-os num único padrão numérico, permitindo comparações justas, independentemente do tamanho dos documentos.

---

Neste documento, não observei exercícios ou secções específicos para completar. No entanto, os passos delineados nos processos, como o pré-processamento e a tokenização, podem ser vistos como atividades práticas a serem implementadas em programas de análise de texto.
