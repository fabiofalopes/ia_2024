# Vector semantics and embeddings

##### What do words mean?

- N-gram or text classification methods we've seen so far
    - Words are just strings (or indices in a vocabulary list)
    - That's not very satisfactory!
- Introductory logic classes:
    - The meaning of "dog" is DOG; cat is CAT
    -
- Old linguistics joke by Barbara Partee in 1967:
    - Q: What's the meaning of life?
    - A: LIFE
- That seems hardly better!

```
wi
```
```
‚àÄ x. DOG ( x ) ‚üπ MAMMAL ( x )
```

What should a theory of word meaning do for us? Let's look at some
desiderata

From **lexical semantics** , the linguistic study of word meaning

## Desiderata


```
From the dictionary:
mouse (N)
```
1. any of numerous small rodents...
2. a hand-operated device that controls a cursor...

## Desiderata

```
senses
```
```
lemma
```
A sense or ‚Äú **concept** ‚Äù is the meaning component of a word
Lemmas can be **polysemous** (have multiple senses)


synonymy

## Relations between senses

- Synonyms have the same meaning in some or all contexts.
    - filbert / hazelnut
    - couch / sofa
    - big / large
    - automobile / car
    - vomit / throw up
    - water / H


synonymy

## Relations between senses

Notice that there are probably no examples of perfect synonymy, even if many aspects of
meaning are identical, word use may differ based on politeness, slang, register, genre, etc.
> **water/H20**. Would it be strange to use ‚ÄùH20" in a surfing guide?
> **big/large** : "my big sister‚Äù is not the same as ‚Äúmy large sister"


##### Linguistic principle of contrast:

```
difference in form -> difference in meaning
So what? No perfect synonyms.
```

Similarity

## Relations between senses

- Words with similar meanings. Not synonyms, but sharing some element of meaning
    - car, bicycle
    - cow, horse
       **word1 word2 similarity**
       vanish disappear 9.
       behave obey 7.
       belief impression 5.
       muscle bone 3.
       modest flexible 0.
       hole agreement 0.

```
If we ask humans about similarity...
```

Relatedness

## Relations between senses

- Also called "word association"
- Words can be related in any way, perhaps via a semantic frame or field
    - coffee, tea: **similar**
    - coffee, cup: **related** , not similar


Words that cover a particular semantic domain and bear structured relations with each other.
**hospitals**
_surgeon, scalpel, nurse, anaesthetic, hospital_
**restaurants**
_waiter, menu, plate, food, menu, chef_
**houses**
_door, roof, kitchen, family, bed_

## Semantic field


Antonymy

## Relations between senses

- Senses that are opposites with respect to only one feature of meaning. Otherwise, they are very similar!
- dark/light short/long fast/slow rise/fall
- hot/cold up/down in/out
- More formally: antonyms can
    - define a binary opposition or be at opposite ends of a scale
    - long/short, fast/slow
    - Be reversives:
    - rise/fall, up/down


Sentiment

**- Words have affective meanings**
    - Positive connotations (happy)
    - Negative connotations (sad)
- **Connotations can be subtle:**
    - Positive connotation: copy, replica, reproduction
    - Negative connotation: fake, knockoff, forgery
- **Evaluation (sentiment!)**
    - Positive evaluation (great, love)
    - Negative evaluation (terrible, hate)

## Connotation


Sentiment

- Words seem to vary along 3 affective dimensions:
    - **valence** : the pleasantness of the stimulus
    - **arousal** : the intensity of emotion provoked by the stimulus
    - **dominance** : the degree of control exerted by the stimulus

## Connotation

```
Word Score Word Score
Valence love 1.000 toxic 0.
happy 1.000 nightmare 0.
Arousal elated 0.960 mellow 0.
frenzy 0.965 napping 0.
Dominance powerful 0.991 weak 0.
lep adershi 0.983 empty 0.
```

## So far...

- Concepts or word senses
    - Have a complex many-to-many association with words (homonymy, multiple senses)
- Have relations with each other
    - Synonymy
    - Antonymy
    - Similarity
    - Relatedness
    - Connotation


Can we build a theory of how to represent word meaning, that accounts for
at least some of the desiderata?

We'll introduce vector semantics

The standard model in language processing

Handles many of our goals

### Computational models of word meaning


```
Ludwig Wittgenstein
```
### ‚ÄúThe meaning of a word is

### its use in the language‚Äù


One way to define "usage":

words are defined by their **environments** (the words around them)

_Zellig Harris_ (1954):

**If A and B have almost identical environments we say that they are synonyms.**

## Defining words according to their use


Suppose you see these sentences:

- Ong choi is delicious saut√©ed with garlic.
- Ong choi is superb over rice
- Ong choi leaves with salty sauces
And you've also seen these:
- ...spinach saut√©ed with garlic over rice
- Chard stems and leaves are delicious
- Collard greens and other salty leafy greens
**Conclusion** :
Ongchoi is a leafy green like spinach, chard, or collard greens
We could conclude this based on words like "leaves" and "delicious" and "sauteed"

## Defining words according to their use


### In fact Ongshoi is a type of water spinach


Defining meaning by linguistic distribution

Let's define the meaning of a word by its distribution in language use, meaning its
neighbouring words or grammatical environments.

## Idea 1


Meaning as a point in space

3 affective dimensions for a word
**valence** : pleasantness
**arousal** : intensity of emotion
**dominance** : the degree of control exerted

## Idea 2

```
Word Score Word Score
Valence love 1.000 toxic 0.008
happy 1.000 nightmare 0.005
Arousal elated 0.960 mellow 0.069
frenzy 0.965 napping 0.046
Dominance powerful 0.991 weak 0.045
lep adershi 0.983 empty 0.081
```
```
Hence the connotation of a word is a vector in 3-space
```

Idea 1: Defining meaning by linguistic distribution

Idea 2: Meaning as a point in multidimensional space


```
Each word = a vector (not just "good" or )
Similar words are "nearby in semantic space"
We build this space automatically by seeing which words are nearby in text
```
_w_ 45

Defining meaning as a point in space based on distribution


## Wo rd m e a n i n g i s a ve c to r

- Called an "embedding" because it's embedded into a vectorial space
- The standard way to represent meaning in NLP
- Every modern NLP algorithm uses embeddings as the representation of word meaning
- Fine-grained model of meaning for similarity


## Wo rd 2 Ve c

- Inspired by the BoW vector representation of documents and words
- Motivated by having words in a vector space that allowed more semantic inference
- Using machine learning to train word vectors by neighbouring words

```
Mikolov, T., et al. 2013). In ADV NEU INF PROC SYS (pp. 3111-3119).
```

How are word embeddings (vectors) trained?

## Wo rd 2 Ve c

```
The m adjusts the vector for b achine learning a a nk to get it more lgorithm
aligned to new context words
Thare well cat meaans thptured in the vector at analogous relafield tionships
```
```
Training examples:
```
1. She went to the bank of the river : (bank, river, go)
2. He deposited some money in the bank: (bank, deposit, money)
In these triplets, bank is the target word, the other words are context words


## Wo rd 2 Ve c

```
27 Mikolov, T., et al. 2013). In ADV NEU INF PROC SYS (pp. 3111-3119).
```
#### ü§¥ üë∏

###### üë®ü¶±

###### üë©ü¶∞

```
Rei Rainha
```
```
Homem Mulher
```
üëë üëë

```
Revolu√ß√£oVetores com muitas dimens√µes treinados com grandes volumes de dados no processamento de linguagem natural em 2013
Cada palavra se posiciona em rela√ß√£o √†s outras Neste exemplo os vetores ilustrativos existem em duas dimens√µes X e Y
Em Problema 1word2vec: palavras em contexto os vetores t√™m 300 dimens√µes para ter suficiente flexibilidade
Problema 2Valores das componentes dos vetores (embeddings) s√£o usados para ajustar : representa√ß√µes de frases, par√°grafos, etc.
posi√ß√£o do vetor de cada palavra em rela√ß√£o aos vetores de outras palavras, mas n√£o t√™m significado espec√≠fico
Queen = King - Man + Woman
```
```
X
```
```
Y
```

## Wo rd 2 Ve c

- Each word has only one vector representation
- If there are many different contexts, word vector is in the middle between them
- This means that contextual semantics is hard in the Word2Vec model

```
Mikolov, T., et al. 2013). In ADV NEU INF PROC SYS (pp. 3111-3119).
```

