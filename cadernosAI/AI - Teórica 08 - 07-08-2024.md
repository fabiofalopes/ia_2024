Quiz 3 - Semana 20 Maio 
Quiz 4 - 13 Junho 
Quiz extra - Dia de exame final

---

# Natural language processing

 Bag of words approach

computational linguistics, nao funciona para as noaces da maneira humana de falar (nao falamos como nos livros)

corpus: caixa de documentos (text), tipicamente tudo numa lingua
- generalistas
- ou expecificos (especializado)

Como definimos relevancia, por exemplo no caso de searsh engine 

cada doc do corpus é um vector

divisão em partes (palavras) processo de tokenização 

dividir docs em listas
se fizermos um set destas listas ficamos com o vocabolario do corpus 

inferencia atraves de frequencia de palavras

parser: identifica partes como sujeito, verbo , etc . cria anotações 

matriz de representações
- words / docs 
	- medimos a relevância das palavras por cada doc para todas as palavras
	- sparse pints  pois temos todo o vocabolio todo e nem todas as palavras estao em todos os docs

matematicamente apos termos 2 vectoes podemos medir angulos entre vetors e neste neste contexto obter a **similiaridade semantica**

Documentos de tamanho muito diferente dentro do mesmo corpos podem criar biases de preferencia felos documentos maiores

normalizar: quantas vezes token aparece / numeros tokens documento = Tf

**normalize term frequency**


IDF(Wi,c) = $log(N/df(wi))$ 

para palavras tipo "que" (stop words) que esta presente em quase, ou todos, os documentos. no caso de que log (~1) = 0

TF(Wi,dj)*IDF(Wi,C)


matrix factorization

non negative matrix factorization 

